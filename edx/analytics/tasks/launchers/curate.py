"""Command-line tool to curate synthetic enrollment event files generated by enrollment validation.

Instructions:

* Use a venv loaded with the pipeline requirements, so that `curate` command is available.

* Determine where enrollment validation jobs output their results.

* Run the `curate` command.

  > curate <location-in-S3-of-enrollment-validation-output> <username> <output-directory> -s <starting-date> > <curation-log>

* Analyze the output written to the <curation-log>.

  The script first copies synthesized event files from each day that
  validation was run, creating subdirectories for each date under the
  <output-directory>.  It then creates "curated" files that are marked
  with the user's <username> and date of curation.

  The script then collects and outputs some statistics about the number
  of events found for a given day.  It outputs for each kind of synthesized
  event on each date what the number of days where synthesized events were
  actually created, the first date, the last date, the average number of events,
  and the variance.  Ideally, for events that are really missing, one
  expects a high number of days (e.g. a week), and a zero variance,
  indicating that the same events were found with each validation run.

  If the number of days is one and the start/end date is the day after the
  synthesized date, then it's very likely to be a transient issue that was
  fixed when a tracking log file was found.

  The script finally outputs those files for which the variance was
  non-zero.  If the variance is very high, then the individual events
  counts should be scrutinized.  It may again be a transient problem
  that was fixed, but reduced to a non-zero number of events instead
  of zero.

* Select and copy curated synthetic event files from <output-directory>
  to synthetic event repository.

  The next step is for the user to select which curated synthetic
  event files to copy to their synthetic event repository.  For files
  with no variance, any one of the generated files could be used.
  It's often more convenient to just find the day that contains a week
  of good data, so that copying is easier.  However, one would want to
  select the files for which any transient problem was fixed.

"""

import argparse
from collections import defaultdict
import datetime
import errno
import glob
import gzip
import json
import os

from edx.analytics.tasks.launchers.s3util import get_s3_files


def create_directory(output_dir):
    """Make sure a directory exists, creating parents as needed."""
    try:
        os.makedirs(output_dir)
    except OSError as exc:
        if exc.errno != errno.EEXIST or os.path.isdir(output_dir):
            raise


def create_curation_metadata(curator, reason, curation_date=None):
    """Create the standard annotation to add to curated synthetic events."""
    if not curation_date:
        curation_date = datetime.datetime.utcnow().isoformat()

    return {
        'curator': curator,
        'reason': reason,
        'curated_at': curation_date,
    }


def categorize_event(event):
    """
    Categorize a synthetic enrollment event based on the reason it was synthesized.

    Output is used as a file prefix, so it should use legal characters.
    """
    reason = event.get('synthesized', {}).get('reason')
    if not reason:
        raise ValueError("Event missing reason for synthesis: {}".format(event))

    if event.get('event_type') == "edx.course.enrollment.mode_changed":
        # The 'validate' check will include ava, dva, dvi, vava.
        # The 'deactivate' includes ad, dd, vad.
        # We do not include da or via here.
        if " => validate" in reason or " => deactivate" in reason:
            return "missing-mode-change"
    else:
        if "start => validate(active)" in reason or "start => deactivate" in reason:
            return "missing-activate"
        elif "deactivate => validate(active)" in reason:
            return "missing-reactivate"
        elif "activate => validate(inactive)" in reason or "validate(active) => validate(inactive)" in reason:
            return "missing-deactivate"
    return None


def get_reason_from_category(category):
    """Create more readable form of category, for use in curation annotation."""
    return category.replace('-', ' ').replace("mode change", "mode_change")


def get_categorized_events(input_filepath):
    """Extract events from synthetic event file, and return by categorization."""
    categorized_events = defaultdict(list)
    with gzip.open(input_filepath, 'r') as input_file:
        for line in input_file:
            event = json.loads(line)
            category = categorize_event(event)
            if category:
                categorized_events[category].append(event)
            else:
                print("Ignoring uncategorized event: {}".format(event))

    return categorized_events


def create_curated_files(input_filepath, output_dir, curator):
    """
    Write curated events to output files according to categorization.

    Events with the same categorization are written to the same output file.
    The categorization is used as the beginning of the filename.

    For example, synthetic_enroll.log-20150513.gz might be read in, and
    generate missing-activate.log-20150513.gz and missing-deactivate.log-20150513.gz
    as output files.
    """
    print("curating input " + input_filepath)
    categorized_events = get_categorized_events(input_filepath)
    curated_events_per_file = defaultdict(list)
    curation_date = datetime.datetime.utcnow().isoformat()
    for category in categorized_events:
        reason = get_reason_from_category(category)
        curation_metadata = create_curation_metadata(curator, reason, curation_date)
        newfilename = os.path.basename(input_filepath).replace("synthetic_enroll", category)
        newfilepath = os.path.join(output_dir, newfilename)

        with gzip.open(newfilepath, 'w') as output_file:
            for event in categorized_events[category]:
                event['curated'] = curation_metadata
                output_file.write(json.dumps(event))
                output_file.write('\n')
                curated_events_per_file[newfilename].append(event)

    return curated_events_per_file


def create_curated_directory(input_dir, output_dir, curator):
    """Generate curated output files for each synthetic enrollment file in the input."""
    curated_events_per_file = {}
    create_directory(output_dir)
    for filename in glob.glob(os.path.join(input_dir, 'synthetic_enroll*')):
        curated_events_per_file.update(create_curated_files(filename, output_dir, curator))
    return curated_events_per_file


def curate_validation_run(source_root_url, end_date, output_root, curator, run_duration):
    """Fetch data corresponding to a particular enrollment validation run, and curate the fetched files."""
    end_date_string = end_date.strftime('%Y-%m-%d')
    print("curating {}-day period ending on date {}".format(run_duration, end_date_string))

    start_date = end_date - datetime.timedelta(days=run_duration)
    source_url = "{}{}-{}".format(source_root_url, start_date.strftime('%Y-%m-%d'), end_date_string)
    dest_root = os.path.join(output_root, end_date_string)
    create_directory(dest_root)
    get_s3_files(source_url, dest_root, ['*gz'])
    output_dir = os.path.join(dest_root, 'curated')
    curated_events_per_file = create_curated_directory(dest_root, output_dir, curator)
    return curated_events_per_file


def compare_curated_files(events_by_file_and_date):
    """
    Look at how files containing synthesized events for a particular day change across runs.

    For each curated output file, output the dates on which it was generated,
    as well as the number of events in that version of the file.
    """
    files_to_check = []
    for filename in sorted(events_by_file_and_date.keys()):
        # First determine if the number of events is constant.
        events_by_date = events_by_file_and_date[filename]
        dates = sorted(events_by_date.keys())
        event_count = [len(events_by_date[date]) for date in dates]
        average = sum(event_count) / len(dates)
        variance = sum([(count - average) * (count - average) for count in event_count])
        print("ENTRY\t{}\t{}\t{}\t{}\t{}\t{}".format(filename, len(dates), dates[0], dates[-1], average, variance))
        if variance > 0:
            files_to_check.append(filename)

    # Go through the files for which we need further details.
    for filename in files_to_check:
        events_by_date = events_by_file_and_date[filename]
        dates = sorted(events_by_date.keys())
        print("Filename: " + filename)
        for date in dates:
            events = events_by_date[date]
            print("   {}: {} ".format(date, len(events)))


def curate_interval(source_root_url, curator, output_root, start_datestring, end_datestring, run_duration):
    """
    Finds all dates between start and end, and curates events generated on each date.

    Also collects the resulting events for each generation date, and
    outputs counts by generation date.
    """
    start_date = datetime.datetime.strptime(start_datestring, '%Y-%m-%d')
    end_date = datetime.datetime.strptime(end_datestring, '%Y-%m-%d')
    if start_date > end_date:
        raise ValueError("Start date {} must precede end date {}".format(start_date, end_date))
    events_by_file_and_date = defaultdict(dict)
    run_date = start_date
    while run_date <= end_date:
        curated_events_per_file = curate_validation_run(source_root_url, run_date, output_root, curator, run_duration)
        run_datestring = run_date.strftime('%Y-%m-%d')
        for filename in curated_events_per_file:
            events_by_file_and_date[filename].update({run_datestring: curated_events_per_file[filename]})
        run_date += datetime.timedelta(days=1)

    compare_curated_files(events_by_file_and_date)


def main():
    """Command-line utility for curating synthetic enrollment events."""
    arg_parser = argparse.ArgumentParser(description='Download and curate synthetic enrollment events.')
    arg_parser.add_argument(
        'input',
        help='URL of S3 bucket root from which to download synthesized enrollment event files.',
    )
    arg_parser.add_argument(
        'curator',
        help='Name of curator running this script.',
    )
    arg_parser.add_argument(
        'output',
        help='Destination root directory to which to download files and create curated events for upload.',
    )
    arg_parser.add_argument(
        '-e', '--end_date',
        help='Last validation-run date for which to download synthetic event files.',
        default=datetime.datetime.utcnow().strftime('%Y-%m-%d'),
    )
    arg_parser.add_argument(
        '-s', '--start_date',
        help='First validation-run date for which to download synthetic event files.',
    )
    arg_parser.add_argument(
        '-r', '--run_duration',
        help='Interval in days of validation-runs.',
        type=int,
        default=7,
    )
    args = arg_parser.parse_args()
    start_datestring = args.start_date
    if start_datestring is None:
        end_date = datetime.datetime.strptime(args.end_date, '%Y-%m-%d')
        start_date = end_date - datetime.timedelta(days=28)
        start_datestring = start_date.strftime('%Y-%m-%d')

    curate_interval(args.input, args.curator, args.output, start_datestring, args.end_date, args.run_duration)


if __name__ == '__main__':
    main()
